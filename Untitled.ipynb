{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import sys, time\n",
    "import dxchange, tomopy\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import rotate\n",
    "from contextlib import closing\n",
    "from multiprocessing import Pool\n",
    "import gc\n",
    "from maximus48 import monochromaticCTF as CTF \n",
    "\n",
    "from maximus48 import var\n",
    "from maximus48 import SSIM_131119 as SSIM_sf \n",
    "from maximus48 import multiCTF2 as multiCTF\n",
    "from maximus48.SSIM_131119 import SSIM_const \n",
    "from maximus48.tomo_proc3 import (Processor, F, tonumpyarray, rotscan)\n",
    "from maximus48 import FSC\n",
    "\n",
    "from pybdv import make_bdv \n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask.array.image import imread\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#from maximus48 import monochromaticCTF as CTF \n",
    "#import h5py\n",
    "#from maximus48.tomo_proc3 import axis_raws, interpolate\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#           parameters for phase retrieval with CTF\n",
    "# =============================================================================\n",
    "N_steps = 10                                                                   # Number of projections per degree\n",
    "N_start = 1                                                                    # index of the first file\n",
    "N_finish = 3600                                                                # index of the last file\n",
    "\n",
    "pixel = 0.1625 * 1e-6                                                          # pixel size \n",
    "distance = np.array((6.1, 6.5, 7.1, 8), dtype = 'float32') * 1e-2              # distances of your measurements \n",
    "energy = 18                                                                    # photon energy in keV\n",
    "beta_delta = 0.15\n",
    "zero_compensation = 0.05\n",
    "ROI = (0,100,2048,2048)                                                        # ROI of the image to be read (x,y,x1,y1 at the image - inverse to numpy!)\n",
    "cp_count = 32                                                                  # number of cores for multiprocessing\n",
    "inclination = -0.23                                                            # angle to compansate the tilt of the rotaxis\n",
    "\n",
    "#data_name = 'ew21_5'\n",
    "data_name = 'Platy-12601'\n",
    "folder = '/g/emcf/schorb/data/HH_platy/raw/'\n",
    "folder_result = '/g/emcf/schorb/data/HH_platy/rec'\n",
    "distances = (1,2,3,4)\n",
    "N_distances  = 4                                                               # number of distances in phase-retrieval\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#    prepartion work \n",
    "# =============================================================================\n",
    "print('\\n##################################################################\\n',\n",
    "      data_name, \"started with %d cpus on\" % cp_count, time.ctime(),\n",
    "      '\\n##################################################################\\n')\n",
    "time1 = time.time()\n",
    "\n",
    "#calculate parameters for phase-retrieval\n",
    "wavelength = var.wavelen(energy)\n",
    "fresnelN = pixel**2/(wavelength*distance)\n",
    "\n",
    "#create save folder if it doesn't exist\n",
    "if not os.path.exists(folder_result):\n",
    "    os.makedirs(folder_result)\n",
    "\n",
    "\n",
    "\n",
    "#%% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "\n",
    "\n",
    "#         DASK \n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "worker_cpu = 8\n",
    "\n",
    "workers_per_job = 2\n",
    "\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    cores=worker_cpu * workers_per_job,\n",
    "    processes=workers_per_job,\n",
    "    memory=\"32GB\",\n",
    "    shebang='#!/usr/bin/env bash',\n",
    "    walltime=\"00:30:00\",\n",
    "    local_directory='/tmp',\n",
    "    death_timeout=\"15s\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "\n",
    "maxnodes = 20\n",
    "\n",
    "ca = cluster.adapt(\n",
    "    minimum = workers_per_job, maximum=maxnodes * workers_per_job,\n",
    "    #target_duration=\"360s\",  # measured in CPU time per worker\n",
    "                             # -> 30 seconds at 12 cores / worker\n",
    "    scale_factor=1.0  # prevent from scaling up because of CPU or MEM need\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a class to store all necessary parameters for parallelization\n",
    "Pro = Processor(ROI, folder, N_start, N_finish, compNpad = 8)                 \n",
    "\n",
    "#set proper paths\n",
    "Pro.init_paths(data_name, folder, distances) \n",
    "\n",
    "#allocate memory to store flatfield\n",
    "shape_ff = (N_distances, len(Pro.flats[0]), Pro.im_shape[0], Pro.im_shape[1]) \n",
    "# ff_shared = F(shape = shape_ff, dtype = 'd')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#read ff-files to memory\n",
    "\n",
    "ff_l =[]\n",
    "\n",
    "for i in range(N_distances):\n",
    "    fname = Pro.flats[i][0].rsplit('_00')[0]\n",
    "    ff_l.append(imread(fname+'*')[:,ROI[1]:ROI[3], ROI[0]:ROI[2]])\n",
    "    \n",
    "ff = da.stack(ff_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate ff-related constants\n",
    "Pro.ROI_ff = (ff.shape[3]//4, ff.shape[2]//4,3 * ff.shape[3]//4, 3 * ff.shape[2]//4)    # make ROI for further flatfield and shift corrections, same logic as for normal ROI\n",
    "ff_con = np.zeros(N_distances, 'object')                                                # array of classes to store flatfield-related constants\n",
    "for i in np.arange(N_distances):    \n",
    "    ff_con[i] = SSIM_const(ff[i][:,Pro.ROI_ff[1]:Pro.ROI_ff[3], \n",
    "                                   Pro.ROI_ff[0]:Pro.ROI_ff[2]].transpose(1,2,0))\n",
    "\n",
    "\n",
    "\n",
    "# #allocate memory to store ff-indexes\n",
    "# indexes = F(shape = (N_finish - N_start, N_distances), dtype = 'i' )\n",
    "\n",
    "# #allocate memory to store shifts\n",
    "# shifts = F(shape = (N_finish - N_start, N_distances, 2), dtype = 'd')\n",
    "\n",
    "# #allocate memory to store filtered files\n",
    "# proj = F(shape = (Pro.N_files, shape_ff[2], shape_ff[3] + 2*Pro.Npad), dtype = 'd' )\n",
    "\n",
    "# #print('finished calculation of ff-constants and memory allocation in ', time.time()-time1)\n",
    "\n",
    "\n",
    "\n",
    "# # =============================================================================\n",
    "# # =============================================================================\n",
    "# # # Processing module\n",
    "# # =============================================================================\n",
    "# # =============================================================================\n",
    "\n",
    "# # =============================================================================\n",
    "# # functions for parallel processing \n",
    "# # =============================================================================\n",
    "\n",
    "# def init():\n",
    "#     global Pro, ff_shared, ff_con, proj\n",
    "\n",
    "def read_flat(j,Pro): \n",
    "    \n",
    "    \"\"\"\n",
    "    j: int\n",
    "        an index of the file that should be processed \n",
    "    Please note, j always starts from zero\n",
    "    To open correct file, images array uses images[i][j + N_start-1]\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    ROI_ff = Pro.ROI_ff\n",
    "    ROI = Pro.ROI\n",
    "    images = Pro.images\n",
    "    N_start = Pro.N_start\n",
    "    Npad = Pro.Npad\n",
    "     \n",
    "    #read image and do ff-retrieval    \n",
    "    filt = []\n",
    "        \n",
    "    imnames = images[0][j].partition('_'+str(distances[0])+'_')[0]+'_*_'+'{:05d}'.format(1)+'.'+images[0][j].partition('.')[-1]\n",
    "    \n",
    "    im = imread(imnames)[:,ROI[1]:ROI[3], ROI[0]:ROI[2]]\n",
    "    maxcorridx = []\n",
    "    \n",
    "    filts = []\n",
    "    \n",
    "    for i in np.arange(len(images)):        \n",
    "        maxcorridx=(dask.delayed(np.argmax)(SSIM_sf.SSIM(SSIM_const(im[i][ROI_ff[1]:ROI_ff[3], ROI_ff[0]:ROI_ff[2]]), \n",
    "                                        ff_con[i]).ssim()))\n",
    "        \n",
    "        filts.append(im[i]/ff[i][maxcorridx.compute()])\n",
    "    \n",
    "    filt = da.stack(filts)\n",
    "    \n",
    "    im_gau0 = var.filt_gauss_laplace(filt[0][ROI_ff[1]:ROI_ff[3], ROI_ff[0]:ROI_ff[2]],\n",
    "                                    sigma = 5)\n",
    "    thisshift = []\n",
    "    \n",
    "    for i in range(len(filt)):\n",
    "        im_gau1 = dask.delayed(var.filt_gauss_laplace)(filt[i][ROI_ff[1]:ROI_ff[3], ROI_ff[0]:ROI_ff[2]],\n",
    "                                    sigma = 5)\n",
    "        thisshift.append(dask.delayed(var.shift_distance)(im_gau0, im_gau1, 10))\n",
    "    \n",
    "    \n",
    "    filt0 = dask.delayed(multiCTF.shift_imageset)(filt, thisshift)\n",
    "\n",
    "    filt0 = dask.delayed(np.pad)(filt0, ((0,0),(Npad, Npad),(Npad, Npad)), 'edge')               # padding with border values\n",
    "    filt0 = dask.delayed(multiCTF.multi_distance_CTF)(filt0, beta_delta, \n",
    "                                          fresnelN, zero_compensation)\n",
    "    filt0 = filt0[Npad:(filt0.shape[0]-Npad),:]\n",
    "    \n",
    "    return filt0\n",
    "    \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Process projections\n",
    "# =============================================================================\n",
    "    \n",
    "#do phase retrieval\n",
    "# time1 = time.time()\n",
    "# with closing(Pool(cp_count, initializer = init)) as pool:    \n",
    "#     pool.map(read_flat, np.arange(Pro.N_files))\n",
    "# #print('time for ff+shifts: ', time.time()-time1)\n",
    "\n",
    "# proj = tonumpyarray(proj.shared_array_base, proj.shape, proj.dtype)\n",
    "\n",
    "\n",
    "res = []\n",
    "for tilt in range(30):\n",
    "    res.append(dask.delayed(read_flat)(tilt,Pro))\n",
    "    \n",
    "da.stack\n",
    "\n",
    "proj = dask.compute(*res)\n",
    "\n",
    "\n",
    "# proj = db.from_delayed(res)\n",
    "\n",
    "\n",
    "#remove vertical stripes with wavelet-fourier filtering\n",
    "time1 = time.time()            \n",
    "# proj = tomopy.prep.stripe.remove_stripe_fw(proj,level=3, wname=u'db25', sigma=2, pad = False)\n",
    "#print('time for stripe removal ', time.time()-time1)\n",
    "\n",
    "proj1 = dask.delayed(tomopy.prep.stripe.remove_stripe_fw)(proj,level=3, wname=u'db25', sigma=2, pad = False)\n",
    "\n",
    "\n",
    "\n",
    "ff = None\n",
    "ff_con = None\n",
    "ff_shared = None\n",
    "indexes = None\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  find rotation axis\n",
    "# =============================================================================\n",
    "\n",
    "# scan the original array to find the inclination\n",
    "#cent, inclination = rotscan(proj, N_steps)\n",
    "\n",
    "#rotate array to compensate for the tilt\n",
    "# proj = rotate(proj, inclination, mode='nearest', axes=(2,1))\n",
    "\n",
    "proj2 = dask.delayed(rotate)(proj1, inclination, mode='nearest', axes=(2,1))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# scan finally\n",
    "cent = dask.delayed(rotscan)(proj2, N_steps)\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# # save what you need and release memory\n",
    "#folder_proj = folder_result + 'proj_delete_after/'\n",
    "#if not os.path.exists(folder_proj):\n",
    "#    os.makedirs(folder_proj) \n",
    "\n",
    "#shifts_2_save = tonumpyarray(shifts.shared_array_base, shifts.shape, shifts.dtype)\n",
    "#np.save(folder_proj + data_name +  '_proj.npy', proj)\n",
    "#np.save(folder_proj + data_name +  '_shifts.npy', shifts_2_save)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#  tomo reconstruction \n",
    "# =============================================================================\n",
    "# 1st reconstruction - all files\n",
    "# n = proj.shape[0]\n",
    "\n",
    "n = proj.npartitions\n",
    "\n",
    "angle = np.pi*np.arange(n)/(N_steps*180)\n",
    "\n",
    "time1 = time.time()\n",
    "outs = dask.delayed(tomopy.recon)(proj, angle, center = cent, algorithm = 'gridrec', filter_name = 'shepp')\n",
    "#print('time for tomo_recon ', time.time()-time1)\n",
    "\n",
    "#crop\n",
    "outs = outs[:,Pro.Npad : outs.shape[1]- Pro.Npad,Pro.Npad : outs.shape[2]- Pro.Npad]\n",
    "\n",
    "#crop additionally\n",
    "#outs = outs[:,270:840, 125:1020]\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# =============================================================================\n",
    "# save as h5    \n",
    "# =============================================================================\n",
    "#cast\n",
    "data = outs\n",
    "data -= data.min()\n",
    "data /= data.max()\n",
    "data *= 32767\n",
    "data = data.astype('int16')\n",
    "gc.collect()\n",
    "\n",
    "# release memory\n",
    "outs = None\n",
    "gc.collect() \n",
    "\n",
    "# set the factors for downscaling, for example 2 times isotropic downsampling by a factor of 2\n",
    "scale_factors = [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]] \n",
    "\n",
    "# set the downsampling mode, 'mean' is good for image data, for binary data or labels\n",
    "# use 'nearest' instead\n",
    "mode = 'interpolate'\n",
    "\n",
    "# resolution of the data, set appropriately\n",
    "resolution = [pixel*1e6 , pixel*1e6 , pixel*1e6] \n",
    "\n",
    "#save big data format\n",
    "folder_h5 = folder_result + 'bdv/'\n",
    "\n",
    "if not os.path.exists(folder_h5):\n",
    "    os.makedirs(folder_h5) \n",
    "\n",
    "\n",
    "# t=dask.delayed(make_bdv)(data, folder_h5 + data_name, downscale_factors=scale_factors,\n",
    "#     ...:                  downscale_mode=mode, resolution=resolution,\n",
    "#     ...:                  unit='micrometer', setup_name = data_name)    \n",
    "\n",
    "# AssertionError: daemonic processes are not allowed to have children\n",
    "\n",
    "make_bdv(data, folder_h5 + data_name, downscale_factors=scale_factors,\n",
    "                 downscale_mode=mode, resolution=resolution,\n",
    "                 unit='micrometer', setup_name = data_name) \n",
    "\n",
    "# =============================================================================\n",
    "# save as tiff\n",
    "# =============================================================================\n",
    "#folder_tiff = folder_result + 'tiff/'\n",
    "\n",
    "#if not os.path.exists(folder_tiff):\n",
    "#    os.makedirs(folder_tiff)\n",
    "\n",
    "#dxchange.write_tiff_stack(data, fname= folder_tiff + data_name + '/tomo')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# save all parameters to the txt file\n",
    "# =============================================================================\n",
    "folder_param = folder_result + 'parameters/' \n",
    "if not os.path.exists(folder_param):\n",
    "    os.makedirs(folder_param) \n",
    "os.mknod(folder_param + data_name + '_parameters.txt')\n",
    "with open(folder_param + data_name + '_parameters.txt', 'w') as f:\n",
    "    f.write(time.ctime() + '\\n')\n",
    "    f.write(\"data_path = %s\\n\" % folder)\n",
    "    f.write(\"ROI =  %s\\n\" % str(ROI))\n",
    "    f.write(\"pixel size = %s\\n\" %str(pixel))\n",
    "    f.write(\"distances = %s\\n\" %str(distance))\n",
    "    f.write(\"energy = %s\\n\" %str(energy))\n",
    "    f.write(\"beta_delta = %s\\n\" %str(beta_delta))\n",
    "    f.write(\"fresnel Number = %s\\n\" %str(fresnelN))\n",
    "    f.write(\"zero_compensation = %s\\n\" %str(zero_compensation))\n",
    "    f.write(\"Npad = %s\\n\" %str(Pro.Npad))\n",
    "    f.write(\"center of rotation = %s\\n\" %str(cent))\n",
    "    f.write(\"projections per degree = %s\\n\" %str(N_steps))\n",
    "    f.write(\"inclination of rotaxis = %s\\n\" %str(inclination))\n",
    "   \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
