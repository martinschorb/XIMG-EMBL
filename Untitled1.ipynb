{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brazilian-least",
   "metadata": {},
   "source": [
    "# Reconstruction of X-Ray tomograms (Hamburg)\n",
    "\n",
    "### start with defining the dataset and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unable-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "from maximus48 import var\n",
    "from maximus48.tomo_proc3 import init_Npad, init_names_custom, F,rotscan\n",
    "from maximus48 import SSIM_131119 as SSIM_sf \n",
    "from maximus48.SSIM_131119 import SSIM_const\n",
    "from maximus48 import multiCTF2 as multiCTF\n",
    "\n",
    "\n",
    "from maximus48.tomo_proc3_parallel import rotaxis_rough\n",
    "\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "# from scipy.ndimage import rotate\n",
    "from maximus48.tomo_proc3_parallel import rotate,rotrough_compute\n",
    "\n",
    "from pybdv import make_bdv \n",
    "\n",
    "from dask import delayed\n",
    "import dask.array as da\n",
    "from dask.array.image import imread\n",
    "from dask.distributed import Client, progress\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "import tomopy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "central-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "#           initial parameters for phase retrieval with CTF\n",
    "# =============================================================================\n",
    "N_steps = 10                                                                   # Number of projections per degree\n",
    "N_start = 1                                                                    # index of the first file\n",
    "N_finish = 3600                                                                # index of the last file\n",
    "\n",
    "pixel = 0.1625 * 1e-6                                                          # pixel size \n",
    "distance = np.array((6.1, 6.5, 7.1, 8), dtype = 'float32') * 1e-2              # distances of your measurements \n",
    "energy = 18                                                                    # photon energy in keV\n",
    "beta_delta = 0.15\n",
    "zero_compensation = 0.05\n",
    "ROI = (0,100,2048,2048) \n",
    "                                                      # ROI of the image to be read (x,y,x1,y1 at the image - inverse to numpy!)\n",
    "cp_count = 60   \n",
    "chunksz = 512\n",
    "\n",
    "                                                               # number of cores for multiprocessing\n",
    "inclination = -0.23                                                            # angle to compansate the tilt of the rotaxis\n",
    "\n",
    "#data_name = 'ew21_5'\n",
    "data_name = 'Platy-12601'\n",
    "folder_base = '/scratch/schorb/HH_platy'\n",
    "folder = os.path.join(folder_base,'raw/')\n",
    "folder_temp = os.path.join(folder_base,'tmp/')\n",
    "folder_result = os.path.join(folder_base,'rec/')\n",
    "distances = (1,2,3,4)\n",
    "N_distances  = 4  \n",
    "\n",
    "\n",
    "#calculate parameters for phase-retrieval\n",
    "wavelength = var.wavelen(energy)\n",
    "fresnelN = pixel**2/(wavelength*distance)\n",
    "\n",
    "\n",
    "#create save folder if it doesn't exist\n",
    "\n",
    "if not os.path.exists(folder_temp):\n",
    "    os.makedirs(folder_temp)\n",
    "\n",
    "\n",
    "if not os.path.exists(folder_result):\n",
    "    os.makedirs(folder_result)\n",
    "\n",
    "\n",
    "# Variable structure:\n",
    "            # ['N_files',\n",
    "            #  'N_start',\n",
    "            #  'Npad',\n",
    "            #  'ROI',\n",
    "            #  'ROI_ff',            \n",
    "            #  'flats',\n",
    "            #  'im_shape',\n",
    "            #  'images',\n",
    "            #  'init_paths']\n",
    "            \n",
    "            \n",
    "Npad = init_Npad(ROI, compression = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Support functions\n",
    "# =============================\n",
    "\n",
    "def init_paths(data_name, path, distance_indexes):\n",
    "    \"\"\"Generate paths images & flatfields\"\"\"\n",
    "\n",
    "    #set data_names\n",
    "    data_names, ff_names = init_names_custom(data_name = data_name,\n",
    "                                             distance_indexes = distance_indexes)\n",
    "    \n",
    "    #find images\n",
    "    imlist = var.im_folder(path)\n",
    "    \n",
    "    # create a filter for unnecessary images\n",
    "    tail = '_00000.tiff'\n",
    "    \n",
    "    if len(data_names[0])!=len(data_names[-1]):\n",
    "        print(\"\"\"\n",
    "        WARNING! Different distances in your dataset \n",
    "        have different naming lengths. \n",
    "        File names can't be arranged. \n",
    "        Try to reduce the number of distances (<10) or modify the script.\n",
    "        \"\"\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        data_lencheck = len(data_names[0]+tail)\n",
    "        ff_lencheck = len(ff_names[0]+tail)\n",
    "    \n",
    "\n",
    "    \n",
    "    #set proper paths\n",
    "    N_distances = len(distance_indexes) \n",
    "    images = np.zeros(N_distances, 'object') \n",
    "    flats = np.zeros(N_distances, 'object')\n",
    "            \n",
    "    for i in np.arange(len(images)):\n",
    "        \n",
    "        #sort image paths\n",
    "        images[i] = [path+im for im in imlist \n",
    "                     if (im.startswith(data_names[i])) \n",
    "                     and not (im.startswith('.'))\n",
    "                     and (len(im) == data_lencheck)]\n",
    "        \n",
    "        flats[i] = [path+im for im in imlist \n",
    "                    if im.startswith(ff_names[i])\n",
    "                    and (len(im)==ff_lencheck)]\n",
    "\n",
    "    return images,flats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================\n",
    "\n",
    "\n",
    "## holographic reconstruction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_flat(j,images=[], ROI_ff=[], ROI=[],flats=[],ff_file='',ffcon_file='',distances=(), N_start=0, Npad=0):\n",
    "    \"\"\"\n",
    "    j: int\n",
    "        an index of the file that should be processed \n",
    "    Please note, j always starts from zero\n",
    "    To open correct file, images array uses images[i][j + N_start-1]\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "        \n",
    "    ff_con = np.load(ffcon_file,allow_pickle=True)\n",
    "    \n",
    "    ff = np.load(ff_file,allow_pickle=True)\n",
    "   \n",
    "    #read image and do ff-retrieval \n",
    "    \n",
    "    # =============================\n",
    "\n",
    "\n",
    "    \n",
    "    ## FLAT field correction\n",
    "    \n",
    "    \n",
    "    filt = []\n",
    "    \n",
    "    for i in np.arange(len(images)):\n",
    "        im = imread(images[i][j])[ROI[1]:ROI[3], ROI[0]:ROI[2]]\n",
    "     \n",
    "        maxcorridx=np.argmax(SSIM_sf.SSIM(SSIM_const(im[ROI_ff[1]:ROI_ff[3], ROI_ff[0]:ROI_ff[2]]),ff_con[i]).ssim())        \n",
    "        filt.append(im/ff[i][maxcorridx])\n",
    "\n",
    "        \n",
    "        \n",
    "    im_gau0 = var.filt_gauss_laplace(filt[0][ROI_ff[1]:ROI_ff[3], ROI_ff[0]:ROI_ff[2]],\n",
    "                                    sigma = 5)\n",
    "    thisshift = []\n",
    "    \n",
    "    for i in range(len(filt)):\n",
    "        im_gau1 = var.filt_gauss_laplace(filt[i][ROI_ff[1]:ROI_ff[3], ROI_ff[0]:ROI_ff[2]],\n",
    "                                    sigma = 5)\n",
    "        thisshift.append(var.shift_distance(im_gau0, im_gau1, 10))\n",
    "    \n",
    "    \n",
    "    filt0 = multiCTF.shift_imageset(filt, thisshift)\n",
    "\n",
    "    filt0 = np.pad(filt0, ((0,0),(Npad, Npad),(Npad, Npad)), 'edge')               # padding with border values\n",
    "    filt0 = multiCTF.multi_distance_CTF(filt0, beta_delta, \n",
    "                                          fresnelN, zero_compensation)\n",
    "    filt0 = filt0[Npad:(filt0.shape[0]-Npad),:]\n",
    "\n",
    "    imsave(os.path.join(folder_temp,''.join(os.path.basename(images[0][j]).partition('_'+str(distances[0]))[0:3:2])),filt0)\n",
    "    # pda = da.from_array(filt0)\n",
    "    # da.to_zarr(pda,'/scratch/schorb/HH_platy/Platy-12601_'+str(j)+'.zarr')\n",
    "\n",
    "    return 'done processing image '+str(j)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-painting",
   "metadata": {},
   "source": [
    "## Holographic reconstruction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "\n",
    "\n",
    "# RUN  SCRIPT\n",
    "\n",
    "# =============================\n",
    "\n",
    "\n",
    "images, flats = init_paths(data_name, folder, distances)\n",
    "\n",
    "im_shape = (ROI[3]-ROI[1], ROI[2]-ROI[0])\n",
    "\n",
    "shape_ff = (N_distances, len(flats[0]), im_shape[0], im_shape[1])\n",
    "ff_shared = F(shape = shape_ff, dtype = 'd')\n",
    "\n",
    "\n",
    "#read ff-files to memory\n",
    "\n",
    "ff = np.zeros(shape_ff)\n",
    "\n",
    "for i in range(N_distances):\n",
    "    for j,fname in enumerate(flats[i]):\n",
    "        ff[i][j]=imread(fname)[ROI[1]:ROI[3], ROI[0]:ROI[2]]\n",
    "        \n",
    "\n",
    "\n",
    "#calculate ff-related constants\n",
    "ROI_ff = (ff.shape[3]//4, ff.shape[2]//4,3 * ff.shape[3]//4, 3 * ff.shape[2]//4)    # make ROI for further flatfield and shift corrections, same logic as for normal ROI\n",
    "\n",
    "\n",
    "ff_con = np.zeros(N_distances, 'object')                                                # array of classes to store flatfield-related constants\n",
    "for i in np.arange(N_distances):    \n",
    "    ff_con[i] = SSIM_const(ff[i][:,ROI_ff[1]:ROI_ff[3], \n",
    "                                    ROI_ff[0]:ROI_ff[2]].transpose(1,2,0))\n",
    "\n",
    "ffcon_file = folder_temp+'ffcon.npy'\n",
    "np.save(ffcon_file,ff_con)\n",
    "\n",
    "\n",
    "\n",
    "ff_file = folder_temp+'ff.npy'\n",
    "np.save(ff_file,ff)\n",
    "\n",
    "\n",
    "#read_flat(j,images=images, ROI_ff=ROI_ff, ROI=ROI,flats=flats,distances=distances,ffcon_file=ffcon_file,ff_file=ff_file, N_start=N_start, Npad=Npad)\n",
    "\n",
    "#%%\n",
    "# s1=client.map....\n",
    "\n",
    "status = 'p'\n",
    "\n",
    "while status != 'done':\n",
    "    for st in s1:\n",
    "        \n",
    "        if st.status in ['error']:\n",
    "            print('retrying '+st.key)\n",
    "            \n",
    "            st.retry()\n",
    "            status = 'p'\n",
    "            time.sleep(1)\n",
    "        elif st.status in ['finished']:\n",
    "            status = 'done'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-antenna",
   "metadata": {},
   "source": [
    "## Stripe removal and storage of intermediate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "imfiles = sorted(glob.glob(folder_temp+'*.tiff'))\n",
    "\n",
    "im = imread(imfiles[0])\n",
    "\n",
    "proj = np.zeros((3600,im.shape[0],im.shape[1]))\n",
    "\n",
    "for idx,imf in enumerate(imfiles):proj[idx,:]=imread(imf)\n",
    "\n",
    "print('stripe removal\\n\\n================================\\n\\n')\n",
    "\n",
    "proj = tomopy.prep.stripe.remove_stripe_fw(proj,level=3, wname=u'db25', sigma=2, pad = False,ncore=cp_count,nchunk=chunksz)\n",
    "\n",
    "pshape = (3600,im.shape[0],im.shape[1])\n",
    "\n",
    "stripe_file = folder_temp+'/stripe.npy'\n",
    "np.save(stripe_file,proj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-separation",
   "metadata": {},
   "source": [
    "## Read data back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "curious-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = np.load(folder_temp+'/stripe.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-heavy",
   "metadata": {},
   "source": [
    "### Make it parallel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "projd = da.from"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
